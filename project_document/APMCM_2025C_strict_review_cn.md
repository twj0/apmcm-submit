# APMCM 2025C 项目严格审查报告（代码、数据与结果）

> 本报告从“严苛评审/审稿人”的角度，对当前仓库中的数据使用方式、模型代码实现及结果输出进行问题排查和改进建议。重点关注：
> - 数据是否充分、来源是否清晰可复现；
> - 代码实现中可能影响可靠性的设计缺陷；
> - 输出结果与统计推断的可信度边界。

---

## 1. 审查范围与依据

- **题面与背景**：`2025/problems/2025 APMCM Problem C.md`
- **数据与配置**：
  - 处理后数据：`2025/data/processed/q1–q5/` 下的样例/面板数据；
  - 配置与随机种子：`2025/src/utils/config.py`；
  - 预处理脚本：`2025/src/preprocessing/prepare_data.py`（仅部分数据流由脚本显式覆盖）。
- **核心模型代码**：
  - Q1：`2025/src/models/q1_soybeans.py`
  - Q2：`2025/src/models/q2_autos.py`
  - Q3：`2025/src/models/q3_semiconductors.py`
  - Q4：`2022025/src/models/q4_tariff_revenue.py`
  - Q5：`2025/src/models/q5_macro_finance.py`、`2025/src/models/q5_transformer_torch.py`
- **结果文件（示例）**：
  - Q1：`results/q1/q1_elasticities.json`、`q1_scenario_exports.csv` 等；
  - Q2：`results/q2/econometric/summary.json`、`results/q2/marl/nash_equilibrium.json`、`results/q2/transformer/training_results.json` 等；
  - Q3：`results/q3/gnn/risk_analysis.json`、`results/q3_policy_scenarios.csv`、`results/q3/ml/*.json` 等；
  - Q4：`results/q4/econometric/*.json`、`results/q4/ml/model_comparison.json` 等；
  - Q5：`results/q5/econometric/*.json`、`results/q5/ml/feature_importance.json`、`results/q5/transformer/*.json` 等。

> 说明：以下所有评价均基于当前仓库内容和代码逻辑本身，不假设外部尚未提供的数据或私有脚本。

---

## 2. 数据使用与处理的主要问题

### 2.1 数据完备性与代表性

- **Q1 大豆：对中国进口侧数据依赖不足**
  - 在 `SoybeanTradeModel.load_q1_data()` 中，当前实现主要基于美国出口数据，经 `HSMapper` 标注大豆，再筛选目的地包含 "China" 的记录。
  - 代码中明确写有注释：
    > "We need to supplement this with Chinese import data from external sources. For now, we'll work with what we have."
  - 问题：
    - 以美国出口记录近似中国进口存在统计误差，无法捕捉 **中国海关统计、统计口径差异、转口贸易** 等因素；
    - 若未真正补充中国官方进口数据，则 **价格弹性与份额弹性估计存在结构性偏差风险**，难以直接外推到真实政策评估。
  - 改进建议：
    - 明确在代码中接入中国海关进口数据（如 UN Comtrade/中国海关数据），对比并合并美国出口与中国进口记录；
    - 在论文中单独一节说明“数据对齐与误差来源”，并做简单一致性检验（如出口与进口总量对比）。

- **多题 processed 数据样本量小、时间跨度有限**
  - 从各题 `data/processed/q*/` 的结构和下游模型要求看，多数面板/序列样本量偏小（年份有限、实体较少）。
  - 对于需要 VAR、GNN、深度学习、MARL 等方法的问题，小样本将：
    - 显著削弱参数估计的稳定性；
    - 放大对初始条件与随机种子的敏感度；
    - 使 **统计显著性和预测性能难以可靠评估**。
  - 建议：
    - 如果条件允许，应在正式比赛提交前，用 **更长时间跨度和更多实体（国家、行业）** 的真实数据替换当前样例；
    - 在论文中明确写出“样本范围”和“样本限制”，避免评委默认是完整官方样本。

### 2.2 原始数据 → processed 数据的复现链条不完整

- 仓库中存在 `2025/src/preprocessing/prepare_data.py` 等预处理脚本，但：
  - 并非所有 `data/processed/q*/*.csv` 都能从现有脚本一步推导出来，部分文件更像是 **事先处理好的结果**；
  - 对于关键面板（如 Q4 的 `q4_0_tariff_revenue_panel.csv`），**缺少从 raw/external 数据到该面板的完整处理流程说明**（缺失值处理、币值统一、价格平减、行业映射等）。
- 风险：
  - 评委/复现实验者难以验证“是否存在有意/无意的数据筛选和 cherry-picking”；
  - 即使你们在本地有完整处理脚本，当前仓库版本也 **无法独立复现**。
- 改进建议：
  - 尽可能将从 `data/raw` 或 `data/external` 到 `data/processed` 的全过程脚本化，并在 README/方法附录中明确“每一个 processed 文件对应的脚本和函数”；
  - 对于确实因赛事篇幅限制无法开放的原始数据，至少在文档中给出“字段列表 + 关键处理步骤（删行/填补/聚合规则）”。

### 2.3 经济计量视角下的潜在遗漏

- 当前面板/时间序列构造中，尚未看到针对以下问题的专门数据处理：
  - **内生性**：例如关税与贸易量/宏观指标可能存在逆向因果；
  - **结构断点**：重大政策事件前后数据分布差异未在数据层显式标记（多靠模型层事件虚拟变量处理）。
- 风险：
  - 若在论文中直接将回归系数解释为因果效应，而未说明上述问题，容易被严格评委指出“识别策略不足”。
- 改进建议：
  - 在数据集里显式增加关键事件的时间标记、结构断点 dummy 等，便于后续模型分段估计或事件研究；
  - 在论文中主动承认：当前样本与识别策略 **更偏相关性分析/情景分析**，不构成严格的因果识别。

---

## 3. 模型代码实现中的主要问题

### 3.1 Q1 大豆贸易模型（`q1_soybeans.py`）

- **(1) 数据构造阶段的“临时方案”未彻底兑现**
  - 如 2.1 所述，`load_q1_data()` 中存在明确 TODO 式注释，但当前版本看不到后续真正接入中国进口数据的代码路径；
  - 这会直接影响后续 `estimate_trade_elasticities()` 的估计基础。

- **(2) 弹性估计的稳健性不足**
  - 代码主要以单一规格（特定控制变量组合）估计价格弹性和份额弹性；
  - 未看到系统的：
    - 子样本检验（不同时间段、不同关税区间）；
    - 不同函数形式（对数、线性、交互项）下弹性的稳健性对比。
  - 结果文件中虽提供了 p 值，但 **对方差估计的假设（异方差、聚类方式）缺乏说明**。

- **(3) LSTM 等深度学习模块的经济含义较弱**
  - 代码中包含大豆 LSTM 预测模块，并对未来进口量进行时间序列预测；
  - 但：
    - 该模块主要基于技术时间序列建模，对政策变量（关税、反制、替代源）等结构性信息利用有限；
    - 样本长度有限下，LSTM 参数远多于有效观测，存在 **明显过拟合风险**。
  - 建议在论文中将 LSTM 描述为 **“补充性时间序列预测尝试”**，不要作为主结论依据。

### 3.2 Q2 日本汽车与产能外移模型（`q2_autos.py`）

- **(1) MARL（多智能体强化学习）环境与奖励函数的经济校验不足**
  - 从整体结构看，`AutoTradeModel.run_marl_analysis()` 使用了多智能体 DRL 框架求解关税—产能外移博弈的均衡策略；
  - 但在当前仓库中：
    - 未见系统的 **baseline 对照实验**（例如与静态博弈/解析解的比对）；
    - 奖励函数的设定和参数权重（利润、就业、关税成本）缺乏定量校验说明；
    - 训练是否稳定、是否存在对初始权重和随机种子高度敏感，暂无报告。
  - 风险：
    - MARL 结果更像是“一组可视化的策略模式示例”，难以视为稳健的政策建议依据。
  - 建议：
    - 在论文中明确：MARL 主要用于 **探索可能的动态调整路径**，而非精确求解实际经济体的最优策略；
    - 如有时间，可补充：对同一环境在多组随机种子下的训练结果分布，展示策略的稳定性范围。

- **(2) Transformer 训练与评估设计偏弱**
  - `train_transformer_model()` 中：
    - 仅对长度有限的序列进行单次时间有序切分（80% 训练、20% 测试），无滚动窗口/多折验证；
    - 使用 `train_test_split(..., shuffle=False)` 是对的，但 **缺乏与简单基准模型（AR/ARIMA/线性回归）的对比**。
  - 风险：
    - 可能出现 Transformer 在小样本上“看起来 RMSE 较小”，但只是拟合了有限样本中的噪声；
    - 评委难以判断该模块是否真的优于简单基线。
  - 改进建议：
    - 增加至少一个简单基准（如 AR(1) 或线性回归），在相同测试集上比较误差；
    - 在结果中报告“Transformer 相对基线的误差改善比例”，而不是单独给出一个 RMSE 数值。

### 3.3 Q3 半导体供应链模型（`q3_semiconductors.py`）

- **(1) ML 贸易预测特征过于简化**
  - 在 `run_ml_trade_prediction()` 中，特征仅为 `year_idx` 和 `partner_encoded` 两个变量：
    - 忽略了 **价格、关税、需求、产业链位置等关键经济变量**；
    - 对半导体这种高度技术密集型产品来说，这种特征设定难以捕捉真实驱动力。
  - 虽然这是一个相对“轻量级”模块，但从严格角度看：
    - 该模型 **更像是时间趋势 + 固定效应的非线性拟合**，不具备很强的解释性。

- **(2) ML 结果文件与代码执行状态不完全一致**
  - 之前检查中，`results/q3/ml/risk_forecasting.json`、`trade_predictions.json` 存在为空或近乎空的情况，说明：
    - 对应 ML 模块可能未在当前版本数据上完整运行；
    - 或有运行错误/异常但未在文档中说明。
  - 风险：
    - 如果在论文中引用了“机器学习预测结果”，但仓库中看不到对应的完整输出，容易被认为是 **再现性不足**。
  - 建议：
    - 要么在论文/总览文档中明确声明：相关 ML 部分仅为代码结构展示，未形成稳健量化结论；
    - 要么在比赛前重新运行并检查所有 ML 结果文件，确保与论文叙述一致。

### 3.4 Q4 关税收入与 Laffer 曲线模型（`q4_tariff_revenue.py`）

- **(1) ML 收入预测存在明显“同一数据集上评估”的问题**
  - 在 `train_ml_models()` 中：
    - 使用梯度提升树 `GradientBoostingRegressor` 拟合特征与 `total_revenue`；
    - 随后使用 **同一数据集** `X, y` 计算 RMSE/MAE/R² 并写入 `gb_model_metrics.json`；
    - 没有做任何形式的 **训练/测试划分、交叉验证或时间滚动验证**。
  - 结果：
    - 得到的指标本质上是 **样本内拟合优度**，而不是泛化误差估计；
    - 在小样本情形下，R² 甚至可能非常高，但几乎没有外推价值。
  - 建议（强烈）：
    - 至少在时间序列上保留末若干年作为测试集，以时间有序方式评估预测误差；
    - 在文档中明确写出“当前 ML 结果仅作拟合演示，不代表真实预测能力”。

- **(2) 特征构造与经济解释尚可进一步加强**
  - 当前特征主要包括：`avg_tariff` 及其滞后、变化率与高关税 regime 虚拟变量等；
  - 虽然这些变量在经济直觉上合理，但：
    - 未显式引入 **宏观控制变量**（如 GDP、汇率、进出口总额），导致收入变化很容易被误解为全部由关税变化驱动；
    - 对于“第二任期关税路径”的模拟，如果其他宏观变量保持不变，假设较为强烈。
  - 建议：
    - 对关键情景模拟结果增加一段“敏感性分析”，例如让 GDP 或进口基数按某区间波动，观察收入预测的鲁棒性；
    - 在论文中严格将结论表述为“在其他条件不变的情形下，模型给出的收入变化方向与大致幅度”。

### 3.5 Q5 宏观金融和制造业回流模型

- **(1) ML 回流预测（`train_reshoring_ml`）的小样本问题**
  - 函数中虽然加入了：
    - 特征数量上限 `max_features = min(5, len(df)//3, len(feature_cols))`；
    - 时间有序拆分训练/测试集，并限制树深度和样本分裂规模；
  - 但由于时间序列本身观测点有限，最终有效样本数量仍然偏少（代码中用 `len(df) < 8` 直接短路返回）。
  - 风险：
    - 即使有 RMSE/MAE/R² 指标，其 **方差也可能非常大**，即不同随机种子/子样本会产生截然不同的结果；
    - `feature_importance` 可能在统计上不稳定，很难支持强烈的“因果或决定性因素”论断。
  - 建议：
    - 将该模块结论限定在“指示性、探索性”层面，例如“哪类变量在模型中往往被赋予更高权重”，而非“某变量显著决定回流”；
    - 如可能，合并更多国家/地区样本，构建 panel 型 ML 任务，以提高样本量。

- **(2) Transformer（`q5_transformer_torch.py`）在样本有限下训练轮数较高**
  - 代码中设置 `epochs=200`，并使用 early stopping：
    - 从技术上能在一定程度避免过拟合；
    - 但在十几到几十个时点的时间序列上，这一参数仍偏大。
  - 风险：
    - 即便有 early stopping，模型极易容量过大；
    - 若无与简单 VAR 或 ARIMA 的对比，很难说 Transformer 带来了净收益。
  - 建议：
    - 缩短默认 epochs（如 50–100），并在结果中加入与 VAR 或简单 AR 模型的误差对比；
    - 在文档中强调 Transformer 为“补充性高维非线性预测尝试”。

---

## 4. 结果文件与实验再现性问题

### 4.1 结果文件的完整性不均衡

- 部分关键结果文件内容详实（例如：
  - Q1 的 `q1_elasticities.json` 包含估计系数、p 值等；
  - Q2 的 `summary.json`、`nash_equilibrium.json` 结构清楚；
  - Q4、Q5 的计量结果中包含系数与显著性指标。
- 但也存在以下问题：
  - Q3 的 `results/q3/ml/risk_forecasting.json`、`trade_predictions.json` 在检视时出现为空或仅含空字典的情况，说明：
    - 相关 ML 模块未在当前版本数据上完成稳定运行；
    - 或运行后未正常写出结果。
  - 某些结果只给出点估计，缺乏：
    - 参数置信区间或标准误；
    - 对应图形中的误差带信息；
    - 多次重复试验的结果分布（尤其是 ML/MARL）。

### 4.2 结果与论文叙述的一致性风险

- 若在最终论文中使用了诸如“机器学习预测表明……”、“GNN 风险评分显示……”等表述，但：
  - 仓库里看不到对应的、结构完整且可解析的结果文件；
  - 或结果文件中的数值与论文文字中的数字存在偏差；
- 则在严格评审者眼中，这是 **再现性和可信度上的严重扣分点**。

- 建议：
  - 在比赛提交前，做一次 **“论文↔结果文件” 的逐项核对**：
    - 每一个写在论文里的关键数字，都能在 `results/` 中找到对应来源；
    - 对于找不到来源、或者代码明显不支持的结论，宁可弱化或删除，不要勉强保留。
  - 对未完成/未稳定的模块（例如部分 ML 模块、某些情景模拟），在项目说明中主动标注“未形成稳健结论，不在正文中作为核心结果引用”。

---

## 5. 交叉问题：可重复性与工程实践

- **(1) 随机种子管理**
  - 优点：
    - 在 `utils/config.py` 中定义了 `RANDOM_SEED = 42` 并设置了 `random` 和 `numpy` 的种子；
    - 多数使用随机性的模块（如 RandomForest、GradientBoosting）也设置了 `random_state=42`；
    - Q1、Q2 的 Keras/TensorFlow 模块部分调用了 `tf.random.set_seed(RANDOM_SEED)`；Q5 的 Transformer 也使用了 `torch.manual_seed(RANDOM_SEED)` 和 `np.random.seed(RANDOM_SEED)`。
  - 不足：
    - 对所有涉及随机性的库（尤其是 GPU 上的非确定性 op）并未 100% 控制，虽然在比赛场景下可以接受，但仍应在文档中说明“存在少量数值波动”。

- **(2) 自动化测试与异常处理不足**
  - 仓库中未见系统性的单元测试或集成测试；
  - 多处代码在数据不足时直接返回空字典或空 DataFrame（如长度 < 10/< 20 时），但：
    - 调用方若未检查返回值，可能继续执行后续分析，间接导致“静默失败”。
  - 建议：
    - 至少为各题的主入口函数增加简单的断言或日志检查，例如“若关键步骤返回空结果则终止后续分析并记录错误”；
    - 长期来看，可为关键模块编写小型单元测试（例如：给定玩具数据，检查函数是否能产生预期形状/字段的输出）。

- **(3) 统一运行入口缺失**
  - 目前更多是“每题一个脚本/类”，需要手动调用；
  - 对于评委或助教，缺少一个“一键复现实验”的入口脚本（例如 `run_q1.py`、`run_all.py`）。
  - 建议：
    - 增加简单 CLI 或主脚本，按题号自动：
      - 加载 processed 数据；
      - 运行主要模型；
      - 写出全部核心结果文件；
    - 并在 `project_document` 中提供简明的运行说明。

---

## 6. 综合结论与改进优先级建议

### 6.1 综合评价（严格视角）

- **优点（不在此展开）**：模型框架完整、经济直觉较好、工程结构清晰，这是项目的强项。
- **关键短板集中在三点**：
  1. **数据链条透明度与完备性不足**：部分核心结论依赖的数据在当前仓库中无法从 raw 端完整复现；Q1 对中国进口侧的补数未落实。
  2. **高级模型（ML/MARL/GNN/Transformer）的评估设计与小样本问题**：容易给出“看起来很好”的拟合结果，但缺乏严谨的泛化误差和稳健性分析。
  3. **结果文件与论文叙述的一致性风险**：个别 ML 结果文件为空或半成品，若论文中引用相关结果而未解释，将被视为再现性不足。

### 6.2 改进优先级（在有限时间内可做的事情）

- **P0（强烈建议优先完成）**
  - [ ] 对 Q1：明确补充或说明中国进口数据的处理方案，必要时在正文中将结论降格为“基于出口数据的近似分析”。
  - [ ] 对 Q3：检查并修复 `results/q3/ml/*.json` 为空的问题，或在文档中明确声明“ML 模块未形成稳定结论，本文不依赖其数值”。
  - [ ] 对 Q4/Q5 的 ML 部分：在现有代码基础上增加 **简单的训练/测试分割与基线对比**，避免只报告样本内拟合优度。
  - [ ] 对论文全文：逐条核对关键数值与 `results/` 文件，删除无法在代码/数据中找到来源的“强结论”。

- **P1（有时间应尽量完成）**
  - [ ] 为每题增加一个主运行脚本或 CLI 入口，便于一键复现主要结果；
  - [ ] 在 `project_document` 或 `paper` 附录中，补充一份“数据处理流程图 + 关键字段说明”；
  - [ ] 为最关键的计量模型（Q1 弹性、Q4 Laffer、Q5 回归/VAR）增加 1–2 个简单的敏感性/稳健性检验。

- **P2（时间充裕时的长期优化方向）**
  - [ ] 为 MARL、GNN 和 Transformer 设计一套更系统的评估框架（多随机种子、多子样本、与简单双边模型的对比）；
  - [ ] 为项目引入基础的测试框架（如 pytest），覆盖数据加载和结果写出等关键环节；
  - [ ] 若继续拓展为科研项目，可在识别策略（工具变量、差分、结构模型识别）上做更深入的设计。

---

本报告旨在帮助你们 **提前从严格审稿人的视角审视项目弱点**，以便在有限时间内有针对性地补强“最容易被攻击的环节”。如需，我可以根据本报告进一步帮你们在论文中撰写一节正式的“模型有效性与局限性说明”。
